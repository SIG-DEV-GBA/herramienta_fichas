"""Utilidades de b√∫squeda sem√°ntica en la base de datos de embeddings.

Este m√≥dulo se encarga de recuperar los fragmentos de texto m√°s relevantes para un
campo concreto de la ficha. Durante el desarrollo se duplic√≥ la inicializaci√≥n de
la conexi√≥n con Chroma y se utilizaron dos nombres de colecci√≥n distintos
(`documentos_legales` y `fichas_legales`). Como consecuencia, los embeddings se
almacenaban en una colecci√≥n mientras las consultas se realizaban en otra, lo que
provocaba que no se recuperara ning√∫n fragmento relevante.

Se ha unificado la configuraci√≥n eliminando las inicializaciones duplicadas y
asegurando que tanto la generaci√≥n como la consulta utilicen la misma colecci√≥n
(`documentos_legales`).
"""

import logging
from typing import List

import chromadb
from openai import OpenAI
from dotenv import load_dotenv

from .openai_retry import call_with_retry

load_dotenv()

# Cliente de OpenAI para generar embeddings de las consultas
client = OpenAI()

# Cliente de Chroma para almacenar y consultar los embeddings
chroma_client = chromadb.Client()

# Nombre √∫nico de la colecci√≥n utilizada en toda la aplicaci√≥n
CHROMA_COLLECTION = "documentos_legales"

def buscar_chunks_relevantes(campo: str, doc_id: str, top_n: int = 10) -> List[str]:
    """
    Busca los chunks m√°s relevantes para un campo espec√≠fico de un documento.

    :param campo: texto de la consulta, por ejemplo: 'requisitos de acceso'
    :param doc_id: ID del documento al que pertenecen los chunks
    :param top_n: n√∫mero de chunks a recuperar (por defecto 10)
    :return: lista de textos relevantes
    """
    try:
        # Embedding de la consulta
        embedding_resp = call_with_retry(
            client.embeddings.create,
            model="text-embedding-3-small",
            input=campo,
        )
        embedding = embedding_resp.data[0].embedding

        # Recuperar colecci√≥n y buscar
        collection = chroma_client.get_or_create_collection(name=CHROMA_COLLECTION)

        resultados = collection.query(
            query_embeddings=[embedding],
            n_results=top_n,
            where={"doc_id": doc_id}
        )

        chunks = resultados["documents"][0]
        logging.info(f"üîç Recuperados {len(chunks)} chunks relevantes para campo: {campo}")
        return chunks

    except Exception as e:
        logging.error(f"‚ùå Error en b√∫squeda sem√°ntica para '{campo}': {e}")
        return []
